{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "gxBzFXzgxEha"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##**Pythonで視覚化③：Titanic(seaborn) :binary**\n",
        "Pythonで視覚化③ で使用するデータセットは、視覚化ライブラリ「seaborn」で用意されているデータセットリストにある [Titanic] データセットです。\n",
        "\n",
        "###**このデータセットについて**\n",
        "[Titanic] データセットは、「1912年に北大西洋で氷山に衝突して沈没したタイタニック号への乗客者の生存状況」に関するデータです。\n",
        "このデータセットは、機械学習の初心者向けチュートリアルとして活用されることが多く、Kaggle（100万人以上が利用している世界最大のデータサイエンスコンペティションプラットフォーム）の初心者チュートリアルのデータセットでもあります。\n",
        "\n",
        "seabornデータセットリストにある [Titanic]データセットは、一部のデータ項目名・クラス名がわかりやすい表記に変更され、オリジナルデータにないデータ項目が追加されています。（乗船デッキ）\n",
        "本書では、seaborn版[Titanic]データセットの一部をカット（重複項目）した以下のデータを使用します。\n",
        "\n",
        "- **データ項目（特徴量）**\n",
        " - sex（性別：male、female）\n",
        " - age（年齢）\n",
        " - sibsp（同乗している兄弟/配偶者の数）\n",
        " - parch（タイタニックに同乗している親/子供の数）\n",
        " - fare（乗船料金）\n",
        " - class（乗船クラス：First、Second、Third）\n",
        " - deck（乗船デッキ）\n",
        " - embark_town（出港地：Cherbourg、Queenstown、Southampton）\n",
        " - alone（一人で乗船したかどうか）\n",
        "\n",
        "- **ターゲット（目的変数）**\n",
        " - alive（生存状況：yes、no）\n",
        "\n",
        "### **手順**\n",
        "- 「1．インストール」の「▷」をクリックしてください。（インストールが実行されます）。\n",
        "- Select_Datasetのドロップダウンメニュー(dataset:)で[Titanic(seaborn) :binary]を選択してください。\n",
        "- Load dataset の「▷」をクリックしてください。（データセットが読み込まれます）。"
      ],
      "metadata": {
        "id": "c1ml63p4XFvX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1．インストール**"
      ],
      "metadata": {
        "id": "gxBzFXzgxEha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install seaborn-analyzer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCOw3doQ1kMp",
        "outputId": "3f325add-bfe5-4993-822b-ff0ae727cbe9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting seaborn-analyzer\n",
            "  Downloading seaborn_analyzer-0.2.13-py3-none-any.whl (59 kB)\n",
            "\u001b[K     |████████████████████████████████| 59 kB 4.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.1.3 in /usr/local/lib/python3.7/dist-packages (from seaborn-analyzer) (3.2.2)\n",
            "Collecting lightgbm>=3.3.2\n",
            "  Downloading lightgbm-3.3.3-py3-none-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 15.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from seaborn-analyzer) (1.7.3)\n",
            "Requirement already satisfied: pandas>=1.2.4 in /usr/local/lib/python3.7/dist-packages (from seaborn-analyzer) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.7/dist-packages (from seaborn-analyzer) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn>=0.24.2 in /usr/local/lib/python3.7/dist-packages (from seaborn-analyzer) (1.0.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from seaborn-analyzer) (0.11.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from lightgbm>=3.3.2->seaborn-analyzer) (0.38.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.3->seaborn-analyzer) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.3->seaborn-analyzer) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.3->seaborn-analyzer) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.3->seaborn-analyzer) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib>=3.1.3->seaborn-analyzer) (4.1.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.4->seaborn-analyzer) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=3.1.3->seaborn-analyzer) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24.2->seaborn-analyzer) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24.2->seaborn-analyzer) (1.2.0)\n",
            "Installing collected packages: lightgbm, seaborn-analyzer\n",
            "  Attempting uninstall: lightgbm\n",
            "    Found existing installation: lightgbm 2.2.3\n",
            "    Uninstalling lightgbm-2.2.3:\n",
            "      Successfully uninstalled lightgbm-2.2.3\n",
            "Successfully installed lightgbm-3.3.3 seaborn-analyzer-0.2.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas-bokeh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huIyUa6entHZ",
        "outputId": "c6c6cace-17d1-48c9-97ae-556a85e790ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pandas-bokeh\n",
            "  Downloading pandas_bokeh-0.5.5-py2.py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: bokeh>=2.0 in /usr/local/lib/python3.7/dist-packages (from pandas-bokeh) (2.3.3)\n",
            "Requirement already satisfied: pandas>=0.22.0 in /usr/local/lib/python3.7/dist-packages (from pandas-bokeh) (1.3.5)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from bokeh>=2.0->pandas-bokeh) (2.8.2)\n",
            "Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.7/dist-packages (from bokeh>=2.0->pandas-bokeh) (6.0.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from bokeh>=2.0->pandas-bokeh) (4.1.1)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.7/dist-packages (from bokeh>=2.0->pandas-bokeh) (6.0)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.7/dist-packages (from bokeh>=2.0->pandas-bokeh) (7.1.2)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.7/dist-packages (from bokeh>=2.0->pandas-bokeh) (21.3)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from bokeh>=2.0->pandas-bokeh) (1.21.6)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.7/dist-packages (from bokeh>=2.0->pandas-bokeh) (2.11.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.9->bokeh>=2.0->pandas-bokeh) (2.0.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=16.8->bokeh>=2.0->pandas-bokeh) (3.0.9)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.22.0->pandas-bokeh) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->bokeh>=2.0->pandas-bokeh) (1.15.0)\n",
            "Installing collected packages: pandas-bokeh\n",
            "Successfully installed pandas-bokeh-0.5.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2．データセット読込み**"
      ],
      "metadata": {
        "id": "7avNQxplxTWh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Select_Dataset { run: \"auto\" }\n",
        "#@markdown  **<font color= \"Crimson\">注意</font>：かならず 実行する前に 設定してください。**</font>\n",
        "\n",
        "dataset = 'Titanic(seaborn) :binary' #@param ['Boston_housing :regression', 'Diabetes :regression', 'Breast_cancer :binary','Titanic :binary', 'Titanic(seaborn) :binary', 'Iris :classification', 'Loan_prediction :binary','wine :classification', 'Occupancy_detection :binary', 'Upload']"
      ],
      "metadata": {
        "id": "kYtA-M52ZFGQ",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load dataset\n",
        "\n",
        "#ライブラリインポート\n",
        "#import numpy as np    #数値計算ライブラリ\n",
        "import pandas as pd   #データを効率的に扱うライブラリ\n",
        "import seaborn as sns #視覚化ライブラリ\n",
        "import warnings       #警告を表示させないライブラリ\n",
        "warnings.simplefilter('ignore')\n",
        "\n",
        "'''\n",
        "dataset（ドロップダウンメニュー）で選択したデータセットを読込み、データフレーム（df）に格納。\n",
        "目的変数は、データフレームの最終列とし、FEATURES、TARGET、X、yを指定した後、データフレーム\n",
        "に関する情報と先頭5列を表示。\n",
        "任意のcsvデータを読込む場合は、datasetで'Upload'を選択。\n",
        "\n",
        "'''\n",
        "\n",
        "#任意のcsvデータ読込み及びデータフレーム格納、\n",
        "if dataset =='Upload':\n",
        "  from google.colab import files\n",
        "  uploaded = files.upload()#Upload\n",
        "  target = list(uploaded.keys())[0]\n",
        "  df = pd.read_csv(target)\n",
        "\n",
        "#Diabetes データセットの読込み及びデータフレーム格納、\n",
        "elif dataset == \"Diabetes :regression\":\n",
        "  from sklearn.datasets import load_diabetes\n",
        "  diabetes = load_diabetes()\n",
        "  df = pd.DataFrame(diabetes.data, columns = diabetes.feature_names)\n",
        "  df['target'] = diabetes.target\n",
        "\n",
        "#Breast_cancer データセットの読込み及びデータフレーム格納、\n",
        "elif dataset == \"Breast_cancer :binary\":\n",
        "  from sklearn.datasets import load_breast_cancer\n",
        "  breast_cancer = load_breast_cancer()\n",
        "  df = pd.DataFrame(breast_cancer.data, columns = breast_cancer.feature_names)\n",
        "  #df['target'] = breast_cancer.target  #目的変数をカテゴリー数値とする時\n",
        "  df['target'] = breast_cancer.target_names[breast_cancer.target]\n",
        "\n",
        "#Titanic データセットの読込み及びデータフレーム格納、\n",
        "elif dataset == \"Titanic :binary\":\n",
        "  data_url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
        "  df = pd.read_csv(data_url)\n",
        "  #目的変数 Survived をデータフレーム最終列に移動\n",
        "  X = df.drop(['Survived'], axis=1)\n",
        "  y = df['Survived'] \n",
        "  df = pd.concat([X, y], axis=1)    #X,yを結合し、dfに格納\n",
        "\n",
        "#Titanic(seaborn) データセットの読込み及びデータフレーム格納、\n",
        "elif dataset == \"Titanic(seaborn) :binary\":\n",
        "  df = sns.load_dataset('titanic')\n",
        "  #重複データをカットし、目的変数 alive をデータフレーム最終列に移動\n",
        "  X = df.drop(['survived','pclass','embarked','who','adult_male','alive'], axis=1)\n",
        "  y = df['alive']                   #目的変数データ\n",
        "  df = pd.concat([X, y], axis=1)    #X,yを結合し、dfに格納\n",
        "\n",
        "#iris データセットの読込み及びデータフレーム格納、\n",
        "elif dataset == \"Iris :classification\":\n",
        "  from sklearn.datasets import load_iris\n",
        "  iris = load_iris()\n",
        "  df = pd.DataFrame(iris.data, columns = iris.feature_names)\n",
        "  #df['target'] = iris.target  #目的変数をカテゴリー数値とする時\n",
        "  df['target'] = iris.target_names[iris.target]\n",
        "\n",
        "#wine データセットの読込み及びデータフレーム格納、\n",
        "elif dataset == \"wine :classification\":\n",
        "  from sklearn.datasets import load_wine\n",
        "  wine = load_wine()\n",
        "  df = pd.DataFrame(wine.data, columns = wine.feature_names)\n",
        "  #df['target'] = wine.target  #目的変数をカテゴリー数値とする時\n",
        "  df['target'] = wine.target_names[wine.target]\n",
        "\n",
        "#Loan_prediction データセットの読込み及びデータフレーム格納、 \n",
        "elif dataset == \"Loan_prediction :binary\":\n",
        "  data_url = \"https://github.com/shrikant-temburwar/Loan-Prediction-Dataset/raw/master/train.csv\"\n",
        "  df = pd.read_csv(data_url)\n",
        "\n",
        "#Occupancy_detection データセットの読込み及びデータフレーム格納、 \n",
        "elif dataset =='Occupancy_detection :binary':\n",
        "  data_url = 'https://raw.githubusercontent.com/hima2b4/Auto_Profiling/main/Occupancy-detection-datatest.csv'\n",
        "  df = pd.read_csv(data_url)\n",
        "  df['date'] = pd.to_datetime(df['date'])    #[date]のデータ型をdatetime型に変更\n",
        "\n",
        "#Boston データセットの読込み及びデータフレーム格納 \n",
        "else:\n",
        "  from sklearn.datasets import load_boston\n",
        "  boston = load_boston()\n",
        "  df = pd.DataFrame(boston.data, columns = boston.feature_names)\n",
        "  df['target'] = boston.target\n",
        "\n",
        "#FEATURES、TARGET、X、yを指定 \n",
        "FEATURES = df.columns[:-1]    #説明変数のデータ項目を指定\n",
        "TARGET = df.columns[-1]       #目的変数のデータ項目を指定\n",
        "X = df.loc[:, FEATURES]       #FEATURESのすべてのデータをXに格納\n",
        "y = df.loc[:, TARGET]         #TARGETのすべてのデータをyに格納\n",
        "\n",
        "#データフレーム表示\n",
        "df.info(verbose=True)         #データフレーム情報表示（verbose=Trueで表示数制限カット）\n",
        "df.head()                     #データフレーム先頭5行表示"
      ],
      "metadata": {
        "id": "rwv_xazpmwbC",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Pairplot**"
      ],
      "metadata": {
        "id": "DotwnMt-4jyO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Pairplot_classification\n",
        "\n",
        "from seaborn_analyzer import CustomPairPlot\n",
        "\n",
        "cp = CustomPairPlot()\n",
        "cp.pairanalyzer(df, hue=TARGET)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "3SGV8F469ZhP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **データ項目一覧**\n",
        "#@markdown **※データ項目一覧を表示します。以後のデータ項目の入力は、表示された項目をコピーアンドペーストすると確実です。**\n",
        "print('データ項目名：',df.columns.values)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "osg-N645edaB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3．視覚化**"
      ],
      "metadata": {
        "id": "XCbx_iaHgEiy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **棒グラフ**"
      ],
      "metadata": {
        "id": "diwdoxsLHY8t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title bar-plot_seaborn\n",
        "Column_name =  'xxx'#@param {type:\"raw\"}\n",
        "Category_column_name =  'xxx'#@param {type:\"raw\"}\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set_style('whitegrid') #style指定\n",
        "sns.countplot(x=Column_name, hue=Category_column_name,data=df);"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ORbPqYhqMQOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title bar-plot_seaborn\n",
        "Column_name =  'xxx'#@param {type:\"raw\"}\n",
        "Category_column_name =  'xxx'#@param {type:\"raw\"}\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set_style('whitegrid') #style指定\n",
        "sns.countplot(x=Column_name, hue=Category_column_name,data=df);"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Pkb1Kb-yNXlI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **class_separator_plot**"
      ],
      "metadata": {
        "id": "h8p9b7NrHN_r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title class_separator_plot_plotnine\n",
        "\n",
        "X_column_name = 'xxx'#@param {type:\"raw\"}\n",
        "y_column_name = 'xxx'#@param {type: \"raw\"}\n",
        "Stratified_column_name =  'xxx'#@param {type:\"raw\"}\n",
        "facet = 'xxx~xxx'#@param {type: \"raw\"}\n",
        "\n",
        "from plotnine import *\n",
        "(\n",
        "    ggplot(df)\n",
        "#    + facet_grid(facets  =\"sex~alone\")\n",
        "    + facet_grid(facets = facet) #facetは 'sex~class'のように記述\n",
        "    + aes(x= X_column_name, y= y_column_name, color=Stratified_column_name)\n",
        "    + labs(\n",
        "        x= X_column_name,\n",
        "        y= y_column_name,\n",
        "        title=\"Class separator plot\",\n",
        "    )\n",
        "    + geom_point()\n",
        ")"
      ],
      "metadata": {
        "id": "LkSamMc-vaH4",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}