{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "gxBzFXzgxEha"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##**Pythonで視覚化[Preparation編]**\n",
        "読込んだデータセットに対し、以下のデータクリーニングが実行できます。\n",
        "1．記号識別され欠損データをN.A.(NaN)に置換、2．不要なデータ項目の削除、3．欠損データを含む行を削除、4．カテゴリーデータ項目を Labelエンコード、5．データ項目名を英訳\n",
        "\n",
        "また、クリーニング後のデータで決定木を描画することができます。\n",
        "\n",
        "\n",
        "※参考として、データは数値… データ型は Object とい時の強制数値化 処理も付加しています。\n",
        "***\n",
        "\n",
        "###**手順**\n",
        "- 「1．インストール」の「▷」をクリックしてください。（インストールが実行されます）。\n",
        "- 「2．データセット読込み」Select_Datasetのドロップダウンメニュー(dataset:)よりデータセット\n",
        "を選択してください。（任意のcsvデータを読込む場合は Upload を選択してください）\n",
        "- dataset_type についても、Classification（分類データ）か Regression（回帰データ）のいずれかを選択してください。\n",
        "- Load dataset の「▷」をクリックしてください。（データセットが読み込まれます）。\n",
        "- 「3．データクリーニング」は、上のセルから順に、必要な処理のみを選択しながら、所定項目を入力の上、実行（「▷」をクリック）してください。\n",
        "- 「4．決定木」を実行してください。（木の深さは、[ max_depth: ] で任意に変更できます）\n",
        "\n",
        "***\n",
        "## **csvデータ読み込み時の注意点**\n",
        "- **csvデータの表形式は以下としてください。**\n",
        "\n",
        "|説明変数1|説明変数2|説明変数3|…|説明変数n|…|目的変数|\n",
        "|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n",
        "|data |data|data |…|data |…|data |\n",
        "|data |data|data |…|data |…|data |\n",
        "|･ |･|･ |…|･ |…|･ |\n",
        "|･ |･|･ |…|･ |…|･ |\n",
        "|･ |･|･ |…|･ |…|･ |\n",
        "\n",
        "- [**注意**] csvデータは文字コードを「UTF-8」としてください。\n",
        "\n"
      ],
      "metadata": {
        "id": "299sjPTzkJ3C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1．インストール**"
      ],
      "metadata": {
        "id": "gxBzFXzgxEha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dtreeviz --quiet"
      ],
      "metadata": {
        "id": "MkODXfF57hxR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07f8f7b0-0789-495d-da47-0598f1e0fced"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |████▌                           | 10 kB 22.1 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 20 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 30 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 40 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 51 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 61 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 71 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 72 kB 285 kB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install googletrans==4.0.0-rc1 --quiet"
      ],
      "metadata": {
        "id": "_hue0X6YnHiV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ef42398-9946-4f27-960b-f0d7791056d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 55 kB 1.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 42 kB 567 kB/s \n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 12.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 65 kB 1.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 53 kB 1.1 MB/s \n",
            "\u001b[?25h  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2．データセット読込み**"
      ],
      "metadata": {
        "id": "7avNQxplxTWh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Select_Dataset { run: \"auto\" }\n",
        "#@markdown  **<font color= \"Crimson\">注意</font>：かならず 実行する前に 設定してください。**</font>\n",
        "\n",
        "dataset = 'Titanic(seaborn) :binary' #@param ['Boston_housing :regression', 'Diabetes :regression', 'Breast_cancer :binary','Titanic :binary', 'Titanic(seaborn) :binary', 'Iris :classification', 'Loan_prediction :binary','wine :classification', 'Occupancy_detection :binary', 'Upload']"
      ],
      "metadata": {
        "id": "kYtA-M52ZFGQ",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load dataset\n",
        "\n",
        "#ライブラリインポート\n",
        "import numpy as np\n",
        "import pandas as pd   #データを効率的に扱うライブラリ\n",
        "import seaborn as sns #視覚化ライブラリ\n",
        "import warnings       #警告を表示させないライブラリ\n",
        "warnings.simplefilter('ignore')\n",
        "\n",
        "'''\n",
        "dataset（ドロップダウンメニュー）で選択したデータセットを読込み、データフレーム（df）に格納。\n",
        "目的変数は、データフレームの最終列とし、FEATURES、TARGET、X、yを指定した後、データフレーム\n",
        "に関する情報と先頭5列を表示。\n",
        "任意のcsvデータを読込む場合は、datasetで'Upload'を選択。\n",
        "\n",
        "'''\n",
        "\n",
        "#任意のcsvデータ読込み及びデータフレーム格納、\n",
        "if dataset =='Upload':\n",
        "  from google.colab import files\n",
        "  uploaded = files.upload()#Upload\n",
        "  target = list(uploaded.keys())[0]\n",
        "  df = pd.read_csv(target)\n",
        "\n",
        "#Diabetes データセットの読込み及びデータフレーム格納、\n",
        "elif dataset == \"Diabetes :regression\":\n",
        "  from sklearn.datasets import load_diabetes\n",
        "  diabetes = load_diabetes()\n",
        "  df = pd.DataFrame(diabetes.data, columns = diabetes.feature_names)\n",
        "  df['target'] = diabetes.target\n",
        "\n",
        "#Breast_cancer データセットの読込み及びデータフレーム格納、\n",
        "elif dataset == \"Breast_cancer :binary\":\n",
        "  from sklearn.datasets import load_breast_cancer\n",
        "  breast_cancer = load_breast_cancer()\n",
        "  df = pd.DataFrame(breast_cancer.data, columns = breast_cancer.feature_names)\n",
        "  #df['target'] = breast_cancer.target  #目的変数をカテゴリー数値とする時\n",
        "  df['target'] = breast_cancer.target_names[breast_cancer.target]\n",
        "\n",
        "#Titanic データセットの読込み及びデータフレーム格納、\n",
        "elif dataset == \"Titanic :binary\":\n",
        "  data_url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
        "  df = pd.read_csv(data_url)\n",
        "  #目的変数 Survived をデータフレーム最終列に移動\n",
        "  X = df.drop(['Survived'], axis=1)\n",
        "  y = df['Survived'] \n",
        "  df = pd.concat([X, y], axis=1)    #X,yを結合し、dfに格納\n",
        "\n",
        "#Titanic(seaborn) データセットの読込み及びデータフレーム格納、\n",
        "elif dataset == \"Titanic(seaborn) :binary\":\n",
        "  df = sns.load_dataset('titanic')\n",
        "  #重複データをカットし、目的変数 alive をデータフレーム最終列に移動\n",
        "  X = df.drop(['survived','pclass','embarked','who','adult_male','alive'], axis=1)\n",
        "  y = df['alive']                   #目的変数データ\n",
        "  df = pd.concat([X, y], axis=1)    #X,yを結合し、dfに格納\n",
        "\n",
        "#iris データセットの読込み及びデータフレーム格納、\n",
        "elif dataset == \"Iris :classification\":\n",
        "  from sklearn.datasets import load_iris\n",
        "  iris = load_iris()\n",
        "  df = pd.DataFrame(iris.data, columns = iris.feature_names)\n",
        "  #df['target'] = iris.target  #目的変数をカテゴリー数値とする時\n",
        "  df['target'] = iris.target_names[iris.target]\n",
        "\n",
        "#wine データセットの読込み及びデータフレーム格納、\n",
        "elif dataset == \"wine :classification\":\n",
        "  from sklearn.datasets import load_wine\n",
        "  wine = load_wine()\n",
        "  df = pd.DataFrame(wine.data, columns = wine.feature_names)\n",
        "  #df['target'] = wine.target  #目的変数をカテゴリー数値とする時\n",
        "  df['target'] = wine.target_names[wine.target]\n",
        "\n",
        "#Loan_prediction データセットの読込み及びデータフレーム格納、 \n",
        "elif dataset == \"Loan_prediction :binary\":\n",
        "  data_url = \"https://github.com/shrikant-temburwar/Loan-Prediction-Dataset/raw/master/train.csv\"\n",
        "  df = pd.read_csv(data_url)\n",
        "\n",
        "#Occupancy_detection データセットの読込み及びデータフレーム格納、 \n",
        "elif dataset =='Occupancy_detection :binary':\n",
        "  data_url = 'https://raw.githubusercontent.com/hima2b4/Auto_Profiling/main/Occupancy-detection-datatest.csv'\n",
        "  df = pd.read_csv(data_url)\n",
        "  df['date'] = pd.to_datetime(df['date'])    #[date]のデータ型をdatetime型に変更\n",
        "\n",
        "#Boston データセットの読込み及びデータフレーム格納 \n",
        "else:\n",
        "  from sklearn.datasets import load_boston\n",
        "  boston = load_boston()\n",
        "  df = pd.DataFrame(boston.data, columns = boston.feature_names)\n",
        "  df['target'] = boston.target\n",
        "\n",
        "#データフレーム表示\n",
        "df.info(verbose=True)         #データフレーム情報表示（verbose=Trueで表示数制限カット）\n",
        "df.head()                     #データフレーム先頭5行表示"
      ],
      "metadata": {
        "id": "rwv_xazpmwbC",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **データ項目一覧**\n",
        "#@markdown **※データ項目一覧を表示します。以後のデータ項目の入力は、表示された項目をコピーアンドペーストすると確実です。**\n",
        "print('データ項目名：',df.columns.values)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "d-ZhacAcgUFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3．データクリーニング**"
      ],
      "metadata": {
        "id": "nNhea-EkedRd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 記号識別された欠損データをN.A.(NaN)に置換（☑ ＝実行）\n",
        "#@markdown  ※missing_value_to_nan を☑すると、missing_value_symbol_is で指定した欠損記号をNaNに置換します\n",
        "missing_value_to_nan = True #@param {type:\"boolean\"}\n",
        "missing_value_symbol_is = '---' #@param {type:\"raw\"}\n",
        "\n",
        "#指定記号をNaNに変換\n",
        "if missing_value_to_nan == True:\n",
        "  df = df.replace(missing_value_symbol_is, np.nan)\n",
        "df.head()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "64bMIfHWeeCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 不要なデータ項目の削除（項目名を指定し削除｜7割以上が欠損値の項目を削除☑）\n",
        "#@markdown  **<font color= \"Crimson\">注意</font>：Drop_label_is（カラムを指定して削除）の記載は <u> ' ID ' , ' Age '  </u> などとしてください。**</font>\n",
        "Drop_label_is =  'xxx', 'xxx'#@param {type:\"raw\"}\n",
        "\n",
        "try:\n",
        "  if Drop_label_is is not \"\":\n",
        "    Drop_label_is = pd.Series(Drop_label_is)\n",
        "    print('-----------------------------------------------------------------------------------------')\n",
        "    print(\"Drop of specified column:\", Drop_label_is.values)\n",
        "    df.drop(columns=list(Drop_label_is),axis=1,inplace=True)\n",
        "  else:\n",
        "    print('※削除カラムの指定なし→処理スキップ')\n",
        "except:\n",
        "    print(\"※正常に処理されませんでした。入力に誤りがないか確認してください。\")\n",
        "\n",
        "#データの7割以上が欠損値のカラムを削除（☑ ＝実行）\n",
        "Over_70percent_missing_value_is_drop = True #@param {type:\"boolean\"}\n",
        "\n",
        "#各列ごとに、7割欠損がある列を削除\n",
        "if Over_70percent_missing_value_is_drop == True:\n",
        "  for col in df.columns:\n",
        "    nans = df[col].isnull().sum()  # nanになっている行数をカウント\n",
        "\n",
        "    # nan行数を全行数で割り、7割欠損している列をDrop\n",
        "    if nans / len(df) > 0.7: \n",
        "        # 7割欠損列を削除\n",
        "        print('-----------------------------------------------------------------------------------------')\n",
        "        print(\"Drop of missing 70% column:\", col)\n",
        "        df.drop(col, axis=1, inplace=True)    \n",
        "\n",
        "print('-----------------------------------------------------------------------------------------')\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "gmB7UVYeeq2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 欠損データを含む行を削除（☑ ＝実行）\n",
        "Null_Drop  = True #@param {type:\"boolean\"}\n",
        "\n",
        "if Null_Drop == True:\n",
        "  df = df.dropna(how='any')\n",
        "df.head()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "AWZcUcJYjujU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**✓カテゴリーデータ項目を Labelエンコード** について\n",
        "\n",
        "カテゴリーデータを分析に利用する場合、カテゴリーは数値に変換する必要があります。\n",
        "\n",
        "[NG,OK] を {NG: 0, OK: 1} のようにエンコードする処理です。\n",
        "\n",
        "例えば、カテゴリーデータ項目名が result である場合、**Object_label_to_encode_is** に 'result' と入力し、実行してください。（複数カラムを選択できます）\n",
        "\n",
        "実行後、エンコードの結果とデータセットの先頭5行が表示されます。"
      ],
      "metadata": {
        "id": "o4YDhSNqgwvm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title カテゴリーデータ項目を Labelエンコード（**対象：Dtype が int64, float64 以外のデータ項目**）\n",
        "#@markdown  **<font color= \"Crimson\">注意</font>：指定は <u> ' ID ' , ' Age ' , </u> などとしてください。**\n",
        "Object_label_to_encode_is = 'xxx', 'xxx', 'xxx', 'xxx', 'xxx' #@param {type:\"raw\"}\n",
        "Object_label_to_encode_is = pd.Series(Object_label_to_encode_is)\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "encoders = dict()\n",
        "\n",
        "try:\n",
        "  for i in Object_label_to_encode_is:\n",
        "    if Object_label_to_encode_is is not \"\":\n",
        "      series = df[i]\n",
        "      le = LabelEncoder()\n",
        "      df[i] = pd.Series(\n",
        "        le.fit_transform(series[series.notnull()]),\n",
        "        index=series[series.notnull()].index\n",
        "        )\n",
        "      encoders[i] = le\n",
        "      print('-----------------------------------------------------------------------------------------')\n",
        "      print('[エンコードカラム]：',i)\n",
        "      le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
        "      print(le_name_mapping)\n",
        "    else:\n",
        "      print('skip')\n",
        "\n",
        "except:\n",
        "    print(\"※正常に処理されなかった場合は入力に誤りがないか確認してください。\")\n",
        "print('-----------------------------------------------------------------------------------------') \n",
        "df.head()\n",
        "#https://stackoverflow.com/questions/54444260/labelencoder-that-keeps-missing-values-as-nan"
      ],
      "metadata": {
        "id": "frE8R3FKg0pM",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**✓カラム名を英訳** について\n",
        "\n",
        "この処理は、文字通りカラム名を英訳する処理です。\n",
        "\n",
        "データ分析のライブラリに依存しますが、英字以外では文字化けする場合があり、これに対応させることを意図しています。\n",
        "\n",
        "**Column_English_translation** の☑を外せば、この処理はスルーされます。\n"
      ],
      "metadata": {
        "id": "V6n2Xq9gfRRc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title データ項目名を英訳（☑ ＝実行）\n",
        "Column_English_translation = False #@param {type:\"boolean\"}\n",
        "\n",
        "from googletrans import Translator\n",
        "\n",
        "if Column_English_translation == True:\n",
        "\n",
        "  eng_columns = {}\n",
        "  columns = df.columns\n",
        "  translator = Translator()\n",
        "  \n",
        "  for column in columns:\n",
        "    eng_column = translator.translate(column).text\n",
        "    eng_column = eng_column.replace(' ', '_')\n",
        "    eng_columns[column] = eng_column\n",
        "    df.rename(columns=eng_columns, inplace=True)\n",
        "\n",
        "print('-----------------------------------------------------------------------------------------')\n",
        "print('[カラム名_翻訳結果（翻訳しない場合も表示）]')\n",
        "print('-----------------------------------------------------------------------------------------') \n",
        "df.head(0)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "-e_5yMvafUke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title データクリーニングの最終確認\n",
        "\n",
        "numerical_col = []\n",
        "Object_col = []\n",
        "\n",
        "for col_name, item in df.iteritems():\n",
        "    if item.dtype == object:\n",
        "        Object_col.append(col_name)\n",
        "    else:\n",
        "        numerical_col.append(col_name)\n",
        "        \n",
        "print('-----------------------------------------------------------------------------------------')\n",
        "print('Numerical_colomn:', numerical_col)\n",
        "print('-----------------------------------------------------------------------------------------')\n",
        "print('Object_colomn:', Object_col)\n",
        "print('-----------------------------------------------------------------------------------------')\n",
        "\n",
        "if df.isnull().values.sum()==0:\n",
        "  print('[NA処理判定]')\n",
        "  print('◎：欠損値はありません')\n",
        "else:\n",
        "  print('-----------------------------------------------------------------------------------------')\n",
        "  print('[NA処理判定]')\n",
        "  print('×：欠損値が',df.isnull().values.sum(),'つあります')\n",
        "\n",
        "print('※各カラムのデータ型が[float64]か[int64]なら正しく処理されています')\n",
        "print('-----------------------------------------------------------------------------------------')\n",
        "\n",
        "#データフレーム表示\n",
        "df.info(verbose=True)         #データフレーム情報表示（verbose=Trueで表示数制限カット）\n",
        "df.head()                     #データフレーム先頭5行表示"
      ],
      "metadata": {
        "cellView": "form",
        "id": "fqOaoMORfb1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title データクリーニング結果 csv出力（☑ ＝実行）\n",
        "\n",
        "csv_output = False #@param {type:\"boolean\"}\n",
        "\n",
        "#csv出力\n",
        "if csv_output == True:\n",
        "  df.to_csv('after_prep_data.csv',encoding='utf_8_sig',index=False)\n",
        "  from google.colab import files\n",
        "  files.download('after_prep_data.csv')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "vd0UWrypfowW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4．決定木実行**\n",
        "<details><summary>決定木について</summary><div>\n",
        "決定木はシンプルなほど解釈しやすくなりますので、まずは可読性を重視した決定木を出力するようにしています。（木の深さは2～6に任意設定できます）\n",
        "*   #orientation='LR' の # を消すと、決定木の表示は横向きになります。\n",
        "*   予測したいXの値を X=[X1,X2,X3,X4,…] とすると予測値が表示されます。"
      ],
      "metadata": {
        "id": "rmKE277Gb_GB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **決定木**（木の深さ設定｜max_depth：2～6｜☑ ＝実行） { run: \"auto\" }\n",
        "#Display_decision_tree = True #@param {type:\"boolean\"}\n",
        "\n",
        "dataset_type = 'Classification' #@param [\"Classification\", \"Regression\"]\n",
        "max_depth = 3 #@param {type:\"slider\", min:2, max:6, step:1}\n",
        "\n",
        "\n",
        "#FEATURES、TARGET、X、yを指定 \n",
        "FEATURES = df.columns[:-1]    #説明変数のデータ項目を指定\n",
        "TARGET = df.columns[-1]       #目的変数のデータ項目を指定\n",
        "X = df.loc[:, FEATURES]       #FEATURESのすべてのデータをXに格納\n",
        "y = df.loc[:, TARGET]         #TARGETのすべてのデータをyに格納\n",
        "\n",
        "#dtreeviz import\n",
        "from dtreeviz.trees import *\n",
        "\n",
        "if dataset_type == 'Classification':\n",
        "  CLASS_NAME = list(y.unique())\n",
        "  dtree = tree.DecisionTreeClassifier(max_depth=max_depth)\n",
        "  dtree.fit(X,y)\n",
        "  viz = dtreeviz(dtree,X,y,\n",
        "               target_name = TARGET,\n",
        "               feature_names = FEATURES,\n",
        "               #orientation='LR',\n",
        "               class_names = CLASS_NAME,\n",
        "               fontname='DejaVu Sans',\n",
        "               #X = [3,3,3,5,3]\n",
        "              )\n",
        "\n",
        "if dataset_type == 'Regression':\n",
        "  dtree = tree.DecisionTreeRegressor(max_depth=max_depth)\n",
        "  dtree.fit(X,y)\n",
        "  viz = dtreeviz(dtree,X,y,\n",
        "               target_name = TARGET,\n",
        "               feature_names = FEATURES,\n",
        "               fontname='DejaVu Sans',\n",
        "               #orientation='LR',\n",
        "               #X = [3,3,5,3]\n",
        "              )\n",
        "viz"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ECgs40vqcMTa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **決定木 画像出力（☑ ＝実行）**  { run: \"auto\" }\n",
        "\n",
        "Decision_tree_output = True #@param {type:\"boolean\"}\n",
        "\n",
        "if Decision_tree_output == True:\n",
        "  viz.save('Decission_tree_result.svg')\n",
        "  from google.colab import files\n",
        "  files.download('Decission_tree_result.svg')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "lDoM9XIYcZLt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "bfa4c07b-f424-4c0e-95a1-dbe4c608861a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_5284eda7-35dd-4555-b6ac-09b80d255d18\", \"Decission_tree_result.svg\", 188504)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **参考**"
      ],
      "metadata": {
        "id": "89_FcbFGvx70"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title データは数値… データ型は Object とい時の強制数値化\n",
        "\n",
        "#@markdown **※同じデータ項目にintとfloatが混在している場合、[object]と認識されます。**\n",
        "\n",
        "#@markdown **※これは、強制的にfloatに変換する処理です。**\n",
        "\n",
        "print('■変換結果','\\n')\n",
        "for col in Object_col:\n",
        "  try:\n",
        "    df[col] = df[col].astype('float64')\n",
        "    print('✓',col,'→ change')\n",
        "  except:\n",
        "    print('✓',col,'→ skip')\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "IapQc8Euvw5c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}